# ðŸ¤Ÿ Hi, I'm Alessandro 

Most data science ends with a notebook and some promising results. That's where I like to start.

I'm drawn to the messier, more interesting questions that come after the initial "it works" moment: How do you turn this into something reliable? How do you deploy it without everything breaking? How do you make sure it keeps working when real users start hitting it with real data?

This is where the **engineering mindset** becomes crucial. I approach ML projects like I'm building software that needs to last â€” with proper architecture, testing, monitoring, and documentation. Not because it's required, but because it's the difference between a cool demo and something that actually creates value.

The tools and technologies are constantly evolving, but the fundamentals of good engineering remain the same: write clean code, plan for failure, automate what you can, and always think about the person who has to maintain this six months from now.

## What I'm building right now:

**Production-grade anomaly detection system** â€” taking a computer vision model from "works in the lab" to something you could actually deploy with proper monitoring, health checks, and failure handling.

**End-to-end ML pipelines** â€” because manually running scripts every time new data arrives isn't sustainable. Working with Airflow to orchestrate everything from data ingestion to model retraining.

**WOLLI** â€” my attempt at building a personal AI system that can evolve its own components. It's ambitious, probably overly complex, but it's teaching me a lot about modular architecture and how AI systems should actually be designed.

**Real MLOps workflows** â€” not just training models, but figuring out how to version them, test them, deploy them, and know when they're starting to fail in production.

The goal isn't to collect technologies for the sake of it, but to understand how they fit together to solve actual problems.

---

##  What I work with

**Core languages**: Python (daily), Java, Bash for automation  
**Making things work in production**: Docker, GitHub Actions, Airflow, MLflow  
**Data wrangling & ML**: pandas, NumPy, scikit-learn, PyTorch, OpenCV  
**Cloud platforms**: Azure, AWS, GCP (still learning the differences)  
**Databases**: PostgreSQL, MySQL, Redis when caching matters  
**Environment**: Linux, macOS, terminal-heavy workflow  

---

##  How I think about learning

I don't just want to learn the syntax â€” I want to understand **why things are built the way they are**.

Why does everyone use Docker? What problems does it actually solve? When does Apache Airflow make sense versus just running cron jobs? How do you know if your ML system is actually working in production?

These are the questions that drive me to build things from scratch, break them, and rebuild them better.

This profile is a work in progress, just like my understanding of how to build systems that don't just work, but work reliably.
